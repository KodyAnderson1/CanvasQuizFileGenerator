# Quiz 1- Requires Respondus LockDown Browser

- Number of questions: 15
- Number of [Multiple Choice Questions](#multiple-choice-questions): 11
- Number of [Matching Questions](#matching-questions): 1
- Number of [Multiple Answer Questions](#multiple-answer-questions): 1
- Number of [Multiple Short Answer Questions](#multiple-short-answer-questions): 1 **This section is still being tested. Please report any bugs.**



---


## Multiple Choice Questions
#### The Map function:
1. Performs operations element by element
2. Operates on a partial list of elements
3. Operates on the entire list of elements
4. None of the above.

#### _Answer(s):_ Performs operations element by element

---

#### Input for Reduce phase is:
1. Application input
2. Intermediate data
3. Final result
4. None of the above

#### _Answer(s):_ Intermediate data

---

#### __________ is a columnar storage format.
1. Parquet
2. Avro
3. ORC

#### _Answer(s):_ ORC

---

#### Columnar storage:
1. Is best suited for online analytical processing.
2. Is where data is stored and retrieved in columns.
3. Both of the above
4. None of the above

#### _Answer(s):_ Both of the above

---

#### The Reduce function:
1. Performs operations element by element
2. Operates on a partial list of elements
3. Operates on the entire list of elements
4. None of the above.

#### _Answer(s):_ Operates on the entire list of elements

---

#### All data in the MapReduce Paradigm is represented as a key-value pair. In the key-value pair, the key component is used to identify the data and value component:
1. Is used for sorting
2. Has duplicate information
3. Stores the actual data
4. Does nothing

#### _Answer(s):_ Stores the actual data

---

#### _________ is a row-oriented file format used for serializing big data.
1. ORC
2. Avro
3. Parquet

#### _Answer(s):_ Avro

---

#### What is the default size of HDFS Data block:
1. 16 MB
2. 32 MB
3. 64 MB
4. 128 MB

#### _Answer(s):_ 128 MB

---

#### The master node of the HDFS System is [answer]
1. NameNode
2. Datanode
3. WorkerNode
4. ClientNode

#### _Answer(s):_ NameNode

---

#### Which among the following is a correct statement?
1. NameNode stores meta data
2. DataNodes are the slave processes
3. Both a and b
4. None of the above

#### _Answer(s):_ Both a and b

---

#### The input and output of the MapReduce jobs is stored in:
1. HDFS
2. NameNode
3. ClientNode
4. None of the above

#### _Answer(s):_ HDFS

---

## Matching Questions
#### Match the following:
#### Answer Bank:
1. online transaction system
2. distributed commit log service
3. online analytical processing
4. light-weight messaging system

#### Word Bank:
1. Row-oriented storage
2. Kafka
3. Columnar storage
4. ZeroMQ


#### _Answer(s):_
 
- Row-oriented storage : online transaction system 
- Kafka : distributed commit log service 
- Columnar storage : online analytical processing 
- ZeroMQ : light-weight messaging system

---

## Multiple Answer Questions
HDFS : (select all the correct statements)
1. Is scalable and fault tolerant
2. Has high availability through replication
3. HDFS block is the logical representation of data
4. Store input and output of MapReduce jobs
5. Provides fast access to big files

#### _Answer(s):_
- Is scalable and fault tolerant
- Has high availability through replication
- Store input and output of MapReduce jobs
- Provides fast access to big files

---

## Multiple Short Answer Questions
The two main components of Hadoop are: __________ and __________


#### _Answer(s):_ HDFS, MapReduce

---

